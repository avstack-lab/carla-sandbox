{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c9da28-2001-4932-95bf-f67878eff5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Polygon\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "from avstack.geometry import (\n",
    "    q_cam_to_stan,\n",
    "    q_stan_to_cam,\n",
    "    q_mult_vec,\n",
    "    transformations as tforms,\n",
    ")\n",
    "from avstack.maskfilters import filter_points_in_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f057fa1-285e-4bdc-a206-9f4d83da5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "track_colors = list(mcolors.XKCD_COLORS.keys())\n",
    "\n",
    "\n",
    "def get_track_color(ID_track):\n",
    "    return track_colors[ID_track % len(track_colors)]\n",
    "\n",
    "\n",
    "def get_agent_color(ID_agent):\n",
    "    return agent_colors[ID_agent % len(agent_colors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b185099-1f87-408f-bb17-f2ac7e4e7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cameras = 4\n",
    "\n",
    "# ----------------------------------------\n",
    "# EXTRINSICS -- from 3D world to 3D camera\n",
    "# ----------------------------------------\n",
    "\n",
    "d2r = np.pi / 180\n",
    "pitch = -30\n",
    "\n",
    "# rotation\n",
    "cam_rotations = {\n",
    "    0: q_cam_to_stan\n",
    "    * tforms.transform_orientation([0, pitch * d2r, 45 * d2r], \"euler\", \"quat\"),\n",
    "    1: q_cam_to_stan\n",
    "    * tforms.transform_orientation([0, pitch * d2r, -45 * d2r], \"euler\", \"quat\"),\n",
    "    2: q_cam_to_stan\n",
    "    * tforms.transform_orientation([0, pitch * d2r, -135 * d2r], \"euler\", \"quat\"),\n",
    "    3: q_cam_to_stan\n",
    "    * tforms.transform_orientation([0, pitch * d2r, 135 * d2r], \"euler\", \"quat\"),\n",
    "}\n",
    "\n",
    "# position -- specified in world frame, converted to sensor frame\n",
    "cam_positions = {\n",
    "    0: np.array([0, 0, 4]),\n",
    "    1: np.array([0, 5, 4]),\n",
    "    2: np.array([5, 5, 4]),\n",
    "    3: np.array([5, 0, 4]),\n",
    "}\n",
    "\n",
    "# full transforms\n",
    "cam_extrinsics = {\n",
    "    i: np.block(\n",
    "        [\n",
    "            [\n",
    "                tforms.transform_orientation(\n",
    "                    cam_rotations[i].conjugate(), \"quat\", \"dcm\", n_prec=6\n",
    "                ),\n",
    "                np.reshape(\n",
    "                    q_mult_vec(\n",
    "                        cam_rotations[i].conjugate(), -cam_positions[i], n_prec=6\n",
    "                    ),\n",
    "                    (3, 1),\n",
    "                ),\n",
    "            ],\n",
    "            [np.zeros((1, 3)), np.ones((1, 1))],\n",
    "        ]\n",
    "    )\n",
    "    for i in range(n_cameras)\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "# INTRINSICS - from 3D camera to 2D image\n",
    "# ----------------------------------------\n",
    "width = 2448\n",
    "height = 2048\n",
    "f = 3.5 * 1e-3\n",
    "mx = width / (8.80 * 1e-3)\n",
    "my = height / (6.60 * 1e-3)\n",
    "P_cam = np.array(\n",
    "    [\n",
    "        [f * mx, 0, width / 2, 0],\n",
    "        [0, f * my, height / 2, 0],\n",
    "        [0, 0, 1, 0],\n",
    "    ],\n",
    "    dtype=float,\n",
    ")\n",
    "cam_intrinsics = {i: P_cam for i in range(n_cameras)}\n",
    "img_size = {i: (width, height) for i in range(n_cameras)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e9cc4-ad8b-4726-9d8b-bdcfdb6ce67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discretized grid of points in BEV\n",
    "extent = [[-0.5, 6], [-0.5, 6]]\n",
    "dx = 0.1\n",
    "X, Y = np.meshgrid(*[np.arange(extent[dim][0], extent[dim][1], dx) for dim in range(2)])\n",
    "Z = np.zeros(X.size)\n",
    "pt_bev_tuples = np.vstack([X.ravel(), Y.ravel(), Z])\n",
    "pt_bev_tuples_homog = np.vstack([pt_bev_tuples, np.ones(pt_bev_tuples.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d239ca-0cbc-4882-bf8e-2f9041ae3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the point visibility\n",
    "boundary = {}\n",
    "points_visible = {}\n",
    "for cam in range(1):\n",
    "    # project into camera image plane\n",
    "    pts_in_cam = cam_extrinsics[cam] @ pt_bev_tuples_homog\n",
    "    points_in_img = tforms.project_to_image(pts_in_cam[:3, :].T, cam_intrinsics[cam])\n",
    "    visible_this_cam = filter_points_in_image(pts_in_cam[:3, :].T, cam_intrinsics[cam])\n",
    "\n",
    "    # consistency check\n",
    "    if sum(visible_this_cam) == 0:\n",
    "        raise RuntimeError(f\"No points found in FOV for camera {cam}\")\n",
    "\n",
    "    # perform convex hull estimation for boundary\n",
    "    points_visible[cam] = pt_bev_tuples[:3, visible_this_cam]\n",
    "    hull = ConvexHull(pt_bev_tuples[:2, visible_this_cam].T)\n",
    "    boundary[cam] = np.array(\n",
    "        [pt_bev_tuples[:, visible_this_cam][:2, v] for v in hull.vertices]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310de700-b6e2-4ca5-9c68-c8b5debb1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "fig, ax = plt.subplots()\n",
    "for cam, pos in cam_positions.items():\n",
    "    # camera positions\n",
    "    ax.scatter(\n",
    "        pos[0], pos[1], marker=\"x\", label=f\"Camera {cam}\", color=get_agent_color(cam)\n",
    "    )\n",
    "    # camera pointing angle\n",
    "    length = 0.25\n",
    "    R = tforms.transform_orientation(q_stan_to_cam * cam_rotations[cam])\n",
    "    dx = \n",
    "    dy = \n",
    "    ax.arrow(x=pos[0], y=pos[1], dx=dx, dy=dy, length_includes_head=True,\n",
    "          head_width=0.08, head_length=0.00002)\n",
    "    # camera fovs\n",
    "    p = Polygon(boundary[cam], facecolor=get_agent_color(cam), alpha=0.1)\n",
    "    ax.add_patch(p)\n",
    "    break\n",
    "ax.set_xlim(extent[0])\n",
    "ax.set_ylim(extent[1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e64ac-6a1b-4b27-81b7-3c25e35e8fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a830d303-eeb1-4f93-82f6-4b246dc34ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
