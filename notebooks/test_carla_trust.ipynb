{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avapi.carla import CarlaScenesManager\n",
    "\n",
    "\n",
    "cpath = os.path.join(\"/data/shared/CARLA/multi-agent-intersection/\")\n",
    "CSM = CarlaScenesManager(cpath)\n",
    "idx = 0\n",
    "CDM = CSM.get_scene_dataset_by_index(idx)\n",
    "vid_folder = f\"videos_intersection_{idx}\"\n",
    "\n",
    "print(CSM.scenes)\n",
    "print(f\"{len(CDM)} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from avapi.visualize.snapshot import show_lidar_bev_with_boxes\n",
    "\n",
    "# load point cloud\n",
    "lidar_sensor = \"lidar-0\"\n",
    "agent = 0\n",
    "frame_idx = 10\n",
    "frame = CDM.get_frames(sensor=lidar_sensor, agent=agent)[frame_idx]\n",
    "pc = CDM.get_lidar(frame=frame, sensor=lidar_sensor, agent=agent)\n",
    "show_lidar_bev_with_boxes(pc=pc)\n",
    "\n",
    "# run concave hull algorithm\n",
    "hull = pc.concave_hull_bev()\n",
    "plt.plot(-1 * hull[:, 1], hull[:, 0])\n",
    "plt.axis(\"scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Multi-Agent Tracking and Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avstack.geometry import (\n",
    "    Sphere,\n",
    "    GlobalOrigin3D,\n",
    "    transform_orientation,\n",
    "    Box3D,\n",
    "    Position,\n",
    "    Attitude,\n",
    ")\n",
    "from avstack.calibration import LidarCalibration\n",
    "from avstack.modules.perception.detections import BoxDetection\n",
    "from avstack.modules.perception.object3d import MMDetObjectDetector3D\n",
    "from avstack.modules.tracking.tracker3d import BasicBoxTracker3D\n",
    "from avstack.modules.tracking.stonesoup import StoneSoupKalmanTracker3DBox\n",
    "from avstack.modules.tracking.multisensor import MeasurementBasedMultiTracker\n",
    "\n",
    "from avstack.datastructs import DataContainer\n",
    "\n",
    "\n",
    "# init models\n",
    "# agents = list(range(len(CDM.get_agents(frame=1))))\n",
    "agents = list(range(4))\n",
    "agent_is_static = {\n",
    "    i: \"static\" in CDM.get_agent(frame=1, agent=i).obj_type for i in agents\n",
    "}\n",
    "n_static = sum(list(agent_is_static.values()))\n",
    "print(\n",
    "    \"There are {} agents\\n   {} mobile, {} static\".format(\n",
    "        len(agents), len(agents) - n_static, n_static\n",
    "    )\n",
    ")\n",
    "percep_veh = MMDetObjectDetector3D(model=\"pointpillars\", dataset=\"carla-vehicle\", gpu=0)\n",
    "percep_inf = MMDetObjectDetector3D(\n",
    "    model=\"pointpillars\", dataset=\"carla-infrastructure\", gpu=0\n",
    ")\n",
    "percep_col = None\n",
    "# trackers = {agent: BasicBoxTracker3D() for agent in agents}\n",
    "trackers = {agent: StoneSoupKalmanTracker3DBox() for agent in agents}\n",
    "trackers[\"central\"] = MeasurementBasedMultiTracker(tracker=BasicBoxTracker3D())\n",
    "trackers[\"collab\"] = BasicBoxTracker3D()\n",
    "\n",
    "# init data structures\n",
    "dets = {}\n",
    "tracks = {}\n",
    "imgs_all = {agent: [] for agent in agents}\n",
    "pcs_all = {agent: [] for agent in agents}\n",
    "dets_all = {agent: [] for agent in agents}\n",
    "dets_all[\"collab\"] = []\n",
    "tracks_all = {agent: [] for agent in agents}\n",
    "tracks_all[\"central\"] = []\n",
    "tracks_all[\"collab\"] = []\n",
    "agent_0_frames = CDM.get_frames(sensor=\"lidar-0\", agent=0)[1:-1]\n",
    "platforms_all = {agent: [] for agent in agents}\n",
    "\n",
    "# flags for this run\n",
    "run_distributed_perception = True\n",
    "run_distributed_tracking = True\n",
    "run_centralized_tracking = True\n",
    "run_collaborative_perception = False\n",
    "run_collaborative_tracking = False\n",
    "\n",
    "# run loop\n",
    "n_frames_max = 2000\n",
    "ego_agent = agents[0]\n",
    "for frame in tqdm(agent_0_frames[: min(n_frames_max, len(agent_0_frames))]):\n",
    "    found_data = False\n",
    "    fovs = {}\n",
    "    platforms = {}\n",
    "    perception_input = {}\n",
    "    for agent in agents:\n",
    "        ###############################################\n",
    "        # GET DATA\n",
    "        ###############################################\n",
    "        lidar_sensor = \"lidar-0\"\n",
    "        camera_sensor = \"camera-0\"\n",
    "        img = CDM.get_image(frame=frame, sensor=camera_sensor, agent=agent)\n",
    "        pc = CDM.get_lidar(frame=frame, sensor=lidar_sensor, agent=agent)\n",
    "        imgs_all[agent].append(img)\n",
    "        pcs_all[agent].append(pc)\n",
    "        objs = CDM.get_objects(frame=frame, sensor=lidar_sensor, agent=agent)\n",
    "        calib = CDM.get_calibration(frame=frame, sensor=lidar_sensor, agent=agent)\n",
    "        fovs[agent] = pc.concave_hull_bev()\n",
    "        # fovs[agent] = Sphere(radius=100)\n",
    "        platforms[agent] = calib.reference\n",
    "        platforms_all[agent].append(calib.reference)\n",
    "\n",
    "        ###############################################\n",
    "        # DISTRIBUTED PERCEPTION\n",
    "        ###############################################\n",
    "        found_data = True\n",
    "        if run_distributed_perception:\n",
    "            if agent_is_static[agent]:\n",
    "                dets[agent] = percep_inf(pc)\n",
    "            else:\n",
    "                dets[agent] = percep_veh(pc)\n",
    "            dets_all[agent].append(dets[agent])\n",
    "\n",
    "        ###############################################\n",
    "        # DISTRIBUTED TRACKING USING DISTRIBUTED PERCEP\n",
    "        ###############################################\n",
    "        if run_distributed_tracking:\n",
    "            assert run_distributed_perception\n",
    "            tracks[agent] = trackers[agent](\n",
    "                dets[agent], platform=calib.reference, calibration=calib\n",
    "            )\n",
    "            if not isinstance(tracks[agent], DataContainer):\n",
    "                raise\n",
    "            tracks_all[agent].append([track.box3d.copy() for track in tracks[agent]])\n",
    "\n",
    "    ###############################################\n",
    "    # COLLABORATIVE PERCEPTION/TRACKING\n",
    "    ###############################################\n",
    "    if run_collaborative_perception:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    ###############################################\n",
    "    # CENTRALIZED TRACKING USING DISTRIBUTED PERCEP\n",
    "    ###############################################\n",
    "    # run central tracker on all detections\n",
    "    if found_data:\n",
    "        if run_centralized_tracking:\n",
    "            # Run trust model\n",
    "\n",
    "            # Run tracking\n",
    "            tracks[\"central\"] = trackers[\"central\"](\n",
    "                detections=dets,\n",
    "                fovs=fovs,\n",
    "                platforms=platforms,\n",
    "            )\n",
    "            tracks_all[\"central\"].append(tracks[\"central\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_agent_movies, make_central_movie, make_collab_movie\n",
    "\n",
    "# agent-specific movie\n",
    "if run_distributed_tracking:\n",
    "    print(\"Making distributed agent movies\")\n",
    "    extent = [[-70, 70], [-70, 70], [-100, 100]]\n",
    "    for agent in agents:\n",
    "        make_agent_movies(\n",
    "            imgs=imgs_all[agent],\n",
    "            pcs=pcs_all[agent],\n",
    "            dets=dets_all[agent],\n",
    "            tracks=tracks_all[agent],\n",
    "            agent=agent,\n",
    "            extent=extent,\n",
    "            percep_movies=False,\n",
    "            track_movies=True,\n",
    "            img_movies=True,\n",
    "            bev_movies=True,\n",
    "            vid_folder=vid_folder,\n",
    "        )\n",
    "\n",
    "\n",
    "# central tracking movie\n",
    "if run_centralized_tracking:\n",
    "    print(\"Making centralized tracking movies\")\n",
    "    extent = [[-150, 20], [-80, 40], [-100, 100]]\n",
    "    make_central_movie(\n",
    "        pcs_all,\n",
    "        tracks_all[\"central\"],\n",
    "        ego=platforms_all[ego_agent],\n",
    "        extent=extent,\n",
    "        vid_folder=vid_folder,\n",
    "        colormethod=\"channel-4\",\n",
    "    )\n",
    "\n",
    "\n",
    "# collaborative perception movie\n",
    "if run_collaborative_tracking:\n",
    "    print(\"Making collaborative tracking movies\")\n",
    "    extent = [[-150, 20], [-80, 40], [-100, 100]]\n",
    "    make_collab_movie(\n",
    "        pcs_all,\n",
    "        tracks_all[\"collab\"],\n",
    "        ego=platforms_all[ego_agent],\n",
    "        extent=extent,\n",
    "        vid_folder=vid_folder,\n",
    "        colormethod=\"channel-4\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from avstack.geometry import (\n",
    "#     Sphere,\n",
    "#     GlobalOrigin3D,\n",
    "#     transform_orientation,\n",
    "#     Box3D,\n",
    "#     Position,\n",
    "#     Attitude,\n",
    "# )\n",
    "# from avstack.calibration import LidarCalibration\n",
    "# from avstack.modules.perception.detections import BoxDetection\n",
    "# from avstack.modules.perception.object3d import MMDetObjectDetector3D\n",
    "# from avstack.modules.tracking.tracker3d import BasicBoxTracker3D\n",
    "# from avstack.modules.tracking.multisensor import MeasurementBasedMultiTracker\n",
    "\n",
    "# from avstack.datastructs import DataContainer\n",
    "\n",
    "\n",
    "# # init models\n",
    "# # agents = list(range(len(CDM.get_agents(frame=1))))\n",
    "# agents = list(range(4))\n",
    "# agent_is_static = {\n",
    "#     i: \"static\" in CDM.get_agent(frame=1, agent=i).obj_type for i in agents\n",
    "# }\n",
    "# percep_veh = MMDetObjectDetector3D(model=\"pointpillars\", dataset=\"carla-vehicle\", gpu=0)\n",
    "# percep_inf = MMDetObjectDetector3D(model=\"pointpillars\", dataset=\"carla-infrastructure\", gpu=0)\n",
    "# percep_col = None\n",
    "# trackers = {agent: BasicBoxTracker3D() for agent in agents}\n",
    "# trackers[\"central\"] = MeasurementBasedMultiTracker(tracker=BasicBoxTracker3D())\n",
    "# trackers[\"collab\"] = BasicBoxTracker3D()\n",
    "\n",
    "# # init data structures\n",
    "# dets = {}\n",
    "# tracks = {}\n",
    "# imgs_all = {agent: [] for agent in agents}\n",
    "# pcs_all = {agent: [] for agent in agents}\n",
    "# dets_all = {agent: [] for agent in agents}\n",
    "# dets_all[\"collab\"] = []\n",
    "# tracks_all = {agent: [] for agent in agents}\n",
    "# tracks_all[\"central\"] = []\n",
    "# tracks_all[\"collab\"] = []\n",
    "# agent_0_frames = CDM.get_frames(sensor=\"lidar-0\", agent=0)[1:-1]\n",
    "# platforms_all = {agent: [] for agent in agents}\n",
    "\n",
    "# # flags for this run\n",
    "# run_distributed_perception = True\n",
    "# run_distributed_tracking = True\n",
    "# run_centralized_tracking = True\n",
    "# run_collaborative_perception = False\n",
    "# run_collaborative_tracking = False\n",
    "\n",
    "# # run loop\n",
    "# n_frames_max = 2000\n",
    "# ego_agent = agents[0]\n",
    "# for frame in tqdm(agent_0_frames[: min(n_frames_max, len(agent_0_frames))]):\n",
    "#     found_data = False\n",
    "#     fovs = {}\n",
    "#     platforms = {}\n",
    "#     perception_input = {}\n",
    "#     for agent in agents:\n",
    "#         ###############################################\n",
    "#         # GET DATA\n",
    "#         ###############################################\n",
    "#         lidar_sensor = \"lidar-0\"\n",
    "#         camera_sensor = \"camera-0\"\n",
    "#         img = CDM.get_image(frame=frame, sensor=camera_sensor, agent=agent)\n",
    "#         pc = CDM.get_lidar(frame=frame, sensor=lidar_sensor, agent=agent)\n",
    "#         imgs_all[agent].append(img)\n",
    "#         pcs_all[agent].append(pc)\n",
    "#         objs = CDM.get_objects(frame=frame, sensor=lidar_sensor, agent=agent)\n",
    "#         calib = CDM.get_calibration(frame=frame, sensor=lidar_sensor, agent=agent)\n",
    "#         fovs[agent] = Sphere(radius=100)\n",
    "#         platforms[agent] = calib.reference\n",
    "#         platforms_all[agent].append(calib.reference)\n",
    "\n",
    "#         ###############################################\n",
    "#         # DISTRIBUTED PERCEPTION\n",
    "#         ###############################################\n",
    "#         found_data = True\n",
    "#         if run_distributed_perception:\n",
    "#             if agent_is_static[agent]:\n",
    "#                 dets[agent] = percep_inf(pc)\n",
    "#             else:\n",
    "#                 dets[agent] = percep_veh(pc)\n",
    "#             dets_all[agent].append(dets[agent])\n",
    "\n",
    "#         ###############################################\n",
    "#         # DISTRIBUTED TRACKING USING DISTRIBUTED PERCEP\n",
    "#         ###############################################\n",
    "#         if run_distributed_tracking:\n",
    "#             assert run_distributed_perception\n",
    "#             tracks[agent] = trackers[agent](dets[agent], platform=calib.reference)\n",
    "#             if not isinstance(tracks[agent], DataContainer):\n",
    "#                 raise\n",
    "#             tracks_all[agent].append([track.box3d.copy() for track in tracks[agent]])\n",
    "\n",
    "#         ###############################################\n",
    "#         # PREP FOR COLLABORATIVE PERCEPTION\n",
    "#         ###############################################\n",
    "#         # Construct the input data structure for collaborative perception model\n",
    "#         ref_new = pc.reference.get_ground_projected_reference()\n",
    "#         ref_new.x[2] += 1.8  # position as a normal lidar sensor\n",
    "#         calib_new = LidarCalibration(reference=ref_new)\n",
    "#         pc_proj = pc.project(calib_new)\n",
    "#         ref_global = pc_proj.calibration.reference.integrate(start_at=GlobalOrigin3D)\n",
    "#         position = ref_global.x\n",
    "#         attitude = ref_global.q\n",
    "#         euler = transform_orientation(attitude, \"quat\", \"euler\")\n",
    "#         lidar_pose = np.asarray(\n",
    "#             [\n",
    "#                 *position,\n",
    "#                 np.degrees(euler[0]),\n",
    "#                 np.degrees(euler[2]),\n",
    "#                 np.degrees(euler[1]),\n",
    "#             ]\n",
    "#         )\n",
    "#         perception_input[agent] = {\n",
    "#             \"lidar\": pc_proj.data.x,\n",
    "#             # This pose is in OPV2V format (x, y, z, roll, yaw, pitch) and the rotation are in degrees not radians.\n",
    "#             \"lidar_pose\": lidar_pose,\n",
    "#         }\n",
    "\n",
    "#     ###############################################\n",
    "#     # COLLABORATIVE PERCEPTION/TRACKING\n",
    "#     ###############################################\n",
    "#     if run_collaborative_perception:\n",
    "#         pred_bboxes, _ = percep_col.run(perception_input, ego_agent)\n",
    "#         collab_dets = []\n",
    "#         for pred_bbox in pred_bboxes:\n",
    "#             det = BoxDetection(\n",
    "#                 \"lidar-0\",\n",
    "#                 Box3D(\n",
    "#                     position=Position(x=pred_bbox[0:3], reference=platforms[ego_agent]),\n",
    "#                     # Note that Carla coordination has a reverted y axis (?). Taking a negation of yaw seems make it right.\n",
    "#                     attitude=Attitude(\n",
    "#                         q=transform_orientation([0, 0, -pred_bbox[6]], \"euler\", \"quat\"),\n",
    "#                         reference=platforms[ego_agent],\n",
    "#                     ),\n",
    "#                     hwl=pred_bbox[3:6][::-1],\n",
    "#                 ),\n",
    "#                 platforms[ego_agent],\n",
    "#             )\n",
    "#             collab_dets.append(det)\n",
    "#         collab_dets = DataContainer(\n",
    "#             data=collab_dets, frame=frame, timestamp=0, source_identifier=\"collab\"\n",
    "#         )\n",
    "#         dets_all[\"collab\"].append(collab_dets)\n",
    "\n",
    "#     if run_collaborative_tracking:\n",
    "#         tracks[\"collab\"] = trackers[\"collab\"](\n",
    "#             detections=collab_dets,\n",
    "#             platform=platforms[ego_agent],\n",
    "#         )\n",
    "#         tracks_all[\"collab\"].append(tracks[\"collab\"])\n",
    "\n",
    "#     ###############################################\n",
    "#     # CENTRALIZED TRACKING USING DISTRIBUTED PERCEP\n",
    "#     ###############################################\n",
    "#     # run central tracker on all detections\n",
    "#     if found_data:\n",
    "#         if run_centralized_tracking:\n",
    "#             tracks[\"central\"] = trackers[\"central\"](\n",
    "#                 detections=dets,\n",
    "#                 fovs=fovs,\n",
    "#                 platforms=platforms,\n",
    "#             )\n",
    "#             tracks_all[\"central\"].append(tracks[\"central\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e34a3fdfcf3630a80e000f94537b2fb6cfa81418d2199451c8a97cfcbd5f3443"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
